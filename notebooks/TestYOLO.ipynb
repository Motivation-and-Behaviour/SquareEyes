{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "LABELS = open(\"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/coco.names\").read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights and config\n",
    "configpath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov3.cfg\"\n",
    "weightspath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov3.weights\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(configpath, weightspath)\n",
    "\n",
    "# Determine the output layer names\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0]-1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and save to df\n",
    "def predict_and_save(folder, coded_data, conf_thresh=0.2, nms_thresh=0.2):\n",
    "    predict_files = glob.glob(folder + \"/*/*.jpg\")\n",
    "\n",
    "    predictor, prob, image_id = [], [], []\n",
    "    final = pd.DataFrame(columns=[\"id\", \"prediction\", \"confidence\", \"image\"])\n",
    "\n",
    "    not_coded = []\n",
    "\n",
    "    for index, image in enumerate(predict_files):\n",
    "        if coded_data[\"filename\"].str.contains(os.path.basename(image)).any():\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Working on image {index} of {len(predict_files)-1}\")\n",
    "\n",
    "            im = cv2.imread(image)\n",
    "            (H, W) = im.shape[:2]\n",
    "\n",
    "            # Create the blob\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                im, 1 / 255.0, (416, 416), swapRB=True, crop=False\n",
    "            )\n",
    "            net.setInput(blob)\n",
    "            layerOutputs = net.forward(ln)\n",
    "\n",
    "            # Translate the predictions\n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            classIDs = []\n",
    "\n",
    "            for output in layerOutputs:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    classID = np.argmax(scores)\n",
    "                    confidence = scores[classID]\n",
    "\n",
    "                    if confidence > conf_thresh:\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "                        # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "\n",
    "            # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, nms_thresh)\n",
    "\n",
    "            # Append to df\n",
    "            if len(idxs):\n",
    "                for i in idxs.flatten():\n",
    "                    final = final.append(\n",
    "                        {\n",
    "                            \"id\": classIDs[i],\n",
    "                            \"prediction\": LABELS[classIDs[i]],\n",
    "                            \"confidence\": confidences[i],\n",
    "                            \"image\": os.path.basename(image),\n",
    "                        },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "            else:  # no predictions made\n",
    "                final = final.append(\n",
    "                    {\n",
    "                        \"id\": None,\n",
    "                        \"prediction\": None,\n",
    "                        \"confidence\": None,\n",
    "                        \"image\": os.path.basename(image),\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test against Bridget's coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image 4495 of 4495\n",
      "CPU times: user 3h 8min 40s, sys: 1min 51s, total: 3h 10min 31s\n",
      "Wall time: 57min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coded_data = pd.read_csv(\"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/Screen Time Coding Data - Device.csv\")\n",
    "folder = \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images\"\n",
    "df = predict_and_save(folder, coded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()\n",
    "df.to_csv(\n",
    "    \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/YOLO.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maybe = [\n",
    "    \"mouse\",\n",
    "    \"remote\",\n",
    "    \"keyboard\",\n",
    "]\n",
    "\n",
    "cat_def = [\n",
    "    \"tvmonitor\",\n",
    "    \"laptop\",\n",
    "    \"cell phone\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['screen_def'] = np.where(df[\"prediction\"].isin(cat_def),1,0)\n",
    "df['screen_maybe'] = np.where(df[\"prediction\"].isin(cat_def + cat_maybe),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_def(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_def\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def conf_maybe(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_maybe\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(0.2, 0.51,0.05):\n",
    "    df[\"screen_def_\"+str(x)] = df.apply(conf_def, confthresh=x, axis=1)\n",
    "    df[\"screen_maybe_\"+str(x)] = df.apply(conf_maybe, confthresh=x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(coded_data,left_on=\"image\", right_on=\"filename\")\n",
    "df.drop(columns=\"filename\", inplace=True)\n",
    "df[[\"device\",\"device_excl_bkg\"]] = df[[\"device\",\"device_excl_bkg\"]].astype(int)\n",
    "df = df.drop(columns=[\"prediction\",\"confidence\",\"id\"]).groupby([\"image\"]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['screen_def', 'screen_maybe', 'screen_def_0.2', 'screen_maybe_0.2',\n",
       "       'screen_def_0.25', 'screen_maybe_0.25', 'screen_def_0.3',\n",
       "       'screen_maybe_0.3', 'screen_def_0.35', 'screen_maybe_0.35',\n",
       "       'screen_def_0.39999999999999997', 'screen_maybe_0.39999999999999997',\n",
       "       'screen_def_0.44999999999999996', 'screen_maybe_0.44999999999999996',\n",
       "       'screen_def_0.49999999999999994', 'screen_maybe_0.49999999999999994',\n",
       "       'device', 'device_excl_bkg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_devices = ['device', 'device_excl_bkg']\n",
    "predicted_devices = df.drop(columns=['device', 'device_excl_bkg','screen_def', 'screen_maybe',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing: device & screen_def_0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.94      0.76      1484\n",
      "        True       0.96      0.73      0.83      3011\n",
      "\n",
      "    accuracy                           0.80      4495\n",
      "   macro avg       0.80      0.84      0.80      4495\n",
      "weighted avg       0.86      0.80      0.81      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.94      0.79      1484\n",
      "        True       0.96      0.78      0.86      3011\n",
      "\n",
      "    accuracy                           0.83      4495\n",
      "   macro avg       0.82      0.86      0.82      4495\n",
      "weighted avg       0.87      0.83      0.84      4495\n",
      "\n",
      "Comparing: device & screen_def_0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.95      0.75      1484\n",
      "        True       0.97      0.71      0.82      3011\n",
      "\n",
      "    accuracy                           0.79      4495\n",
      "   macro avg       0.79      0.83      0.78      4495\n",
      "weighted avg       0.85      0.79      0.79      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.95      0.78      1484\n",
      "        True       0.97      0.76      0.85      3011\n",
      "\n",
      "    accuracy                           0.82      4495\n",
      "   macro avg       0.81      0.85      0.81      4495\n",
      "weighted avg       0.87      0.82      0.83      4495\n",
      "\n",
      "Comparing: device & screen_def_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.96      0.74      1484\n",
      "        True       0.97      0.68      0.80      3011\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.78      0.82      0.77      4495\n",
      "weighted avg       0.85      0.77      0.78      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.96      0.77      1484\n",
      "        True       0.97      0.73      0.84      3011\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.81      0.85      0.80      4495\n",
      "weighted avg       0.86      0.81      0.81      4495\n",
      "\n",
      "Comparing: device & screen_def_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.96      0.73      1484\n",
      "        True       0.97      0.66      0.79      3011\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.81      0.76      4495\n",
      "weighted avg       0.85      0.76      0.77      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.96      0.76      1484\n",
      "        True       0.98      0.72      0.83      3011\n",
      "\n",
      "    accuracy                           0.80      4495\n",
      "   macro avg       0.80      0.84      0.79      4495\n",
      "weighted avg       0.86      0.80      0.80      4495\n",
      "\n",
      "Comparing: device & screen_def_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.97      0.72      1484\n",
      "        True       0.97      0.64      0.77      3011\n",
      "\n",
      "    accuracy                           0.75      4495\n",
      "   macro avg       0.77      0.80      0.74      4495\n",
      "weighted avg       0.84      0.75      0.75      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.96      0.75      1484\n",
      "        True       0.98      0.69      0.81      3011\n",
      "\n",
      "    accuracy                           0.78      4495\n",
      "   macro avg       0.79      0.83      0.78      4495\n",
      "weighted avg       0.85      0.78      0.79      4495\n",
      "\n",
      "Comparing: device & screen_def_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.97      0.71      1484\n",
      "        True       0.98      0.62      0.76      3011\n",
      "\n",
      "    accuracy                           0.73      4495\n",
      "   macro avg       0.77      0.79      0.73      4495\n",
      "weighted avg       0.84      0.73      0.74      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.97      0.74      1484\n",
      "        True       0.98      0.67      0.80      3011\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.79      0.82      0.77      4495\n",
      "weighted avg       0.85      0.77      0.78      4495\n",
      "\n",
      "Comparing: device & screen_def_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.97      0.70      1484\n",
      "        True       0.98      0.60      0.74      3011\n",
      "\n",
      "    accuracy                           0.72      4495\n",
      "   macro avg       0.76      0.79      0.72      4495\n",
      "weighted avg       0.83      0.72      0.73      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.97      0.73      1484\n",
      "        True       0.98      0.66      0.79      3011\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.81      0.76      4495\n",
      "weighted avg       0.85      0.76      0.77      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.91      0.76      1573\n",
      "        True       0.94      0.74      0.83      2922\n",
      "\n",
      "    accuracy                           0.80      4495\n",
      "   macro avg       0.79      0.82      0.79      4495\n",
      "weighted avg       0.84      0.80      0.80      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.91      0.79      1573\n",
      "        True       0.94      0.78      0.85      2922\n",
      "\n",
      "    accuracy                           0.83      4495\n",
      "   macro avg       0.82      0.85      0.82      4495\n",
      "weighted avg       0.85      0.83      0.83      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.92      0.75      1573\n",
      "        True       0.94      0.71      0.81      2922\n",
      "\n",
      "    accuracy                           0.78      4495\n",
      "   macro avg       0.79      0.82      0.78      4495\n",
      "weighted avg       0.83      0.78      0.79      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.92      0.78      1573\n",
      "        True       0.95      0.76      0.84      2922\n",
      "\n",
      "    accuracy                           0.82      4495\n",
      "   macro avg       0.81      0.84      0.81      4495\n",
      "weighted avg       0.85      0.82      0.82      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.93      0.74      1573\n",
      "        True       0.95      0.68      0.80      2922\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.78      0.81      0.77      4495\n",
      "weighted avg       0.83      0.77      0.78      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.93      0.77      1573\n",
      "        True       0.95      0.74      0.83      2922\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.80      0.83      0.80      4495\n",
      "weighted avg       0.85      0.81      0.81      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.94      0.73      1573\n",
      "        True       0.95      0.67      0.78      2922\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.80      0.76      4495\n",
      "weighted avg       0.83      0.76      0.77      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.94      0.76      1573\n",
      "        True       0.95      0.72      0.82      2922\n",
      "\n",
      "    accuracy                           0.80      4495\n",
      "   macro avg       0.80      0.83      0.79      4495\n",
      "weighted avg       0.85      0.80      0.80      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.94      0.72      1573\n",
      "        True       0.95      0.64      0.77      2922\n",
      "\n",
      "    accuracy                           0.75      4495\n",
      "   macro avg       0.77      0.79      0.75      4495\n",
      "weighted avg       0.82      0.75      0.75      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.94      0.75      1573\n",
      "        True       0.96      0.70      0.81      2922\n",
      "\n",
      "    accuracy                           0.78      4495\n",
      "   macro avg       0.79      0.82      0.78      4495\n",
      "weighted avg       0.84      0.78      0.79      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.95      0.72      1573\n",
      "        True       0.96      0.62      0.75      2922\n",
      "\n",
      "    accuracy                           0.74      4495\n",
      "   macro avg       0.77      0.78      0.74      4495\n",
      "weighted avg       0.82      0.74      0.74      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.94      0.74      1573\n",
      "        True       0.96      0.68      0.80      2922\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.79      0.81      0.77      4495\n",
      "weighted avg       0.84      0.77      0.78      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.95      0.71      1573\n",
      "        True       0.96      0.60      0.74      2922\n",
      "\n",
      "    accuracy                           0.72      4495\n",
      "   macro avg       0.76      0.78      0.72      4495\n",
      "weighted avg       0.82      0.72      0.73      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.95      0.74      1573\n",
      "        True       0.96      0.66      0.78      2922\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.80      0.76      4495\n",
      "weighted avg       0.83      0.76      0.77      4495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for true_device in true_devices:\n",
    "    for predicted_device in predicted_devices:\n",
    "        print(f\"Comparing: {true_device} & {predicted_device}\")\n",
    "        print(classification_report(df[true_device], df[predicted_device]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing: device & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.96      0.77      1484\n",
      "        True       0.97      0.73      0.84      3011\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.81      0.85      0.80      4495\n",
      "weighted avg       0.86      0.81      0.81      4495\n",
      "\n",
      "AUC: 0.8465963972173907\n",
      "Comparing: device_excl_bkg & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.93      0.77      1573\n",
      "        True       0.95      0.74      0.83      2922\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.80      0.83      0.80      4495\n",
      "weighted avg       0.85      0.81      0.81      4495\n",
      "\n",
      "0.6092436327761945\n",
      "AUC: 0.8335444811550841\n",
      "Comparing: device & screen_maybe_0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.94      0.79      1484\n",
      "        True       0.96      0.78      0.86      3011\n",
      "\n",
      "    accuracy                           0.83      4495\n",
      "   macro avg       0.82      0.86      0.82      4495\n",
      "weighted avg       0.87      0.83      0.84      4495\n",
      "\n",
      "AUC: 0.8599171635718448\n",
      "Comparing: device_excl_bkg & screen_maybe_0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.94      0.79      1484\n",
      "        True       0.96      0.78      0.86      3011\n",
      "\n",
      "    accuracy                           0.83      4495\n",
      "   macro avg       0.82      0.86      0.82      4495\n",
      "weighted avg       0.87      0.83      0.84      4495\n",
      "\n",
      "AUC: 0.8599171635718448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparing: device & screen_maybe_0.3\")\n",
    "print(classification_report(df[\"device\"], df[\"screen_maybe_0.3\"]))\n",
    "print(f\"AUC: {roc_auc_score(df['device'], df['screen_maybe_0.3'])}\")\n",
    "print(f\"Comparing: device_excl_bkg & screen_maybe_0.3\")\n",
    "print(classification_report(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))\n",
    "print(cohen_kappa_score(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))\n",
    "print(f\"AUC: {roc_auc_score(df['device_excl_bkg'], df['screen_maybe_0.3'])}\")\n",
    "print(f\"Comparing: device & screen_maybe_0.2\")\n",
    "print(classification_report(df[\"device\"], df[\"screen_maybe_0.2\"]))\n",
    "print(f\"AUC: {roc_auc_score(df['device'], df['screen_maybe_0.2'])}\")\n",
    "print(f\"Comparing: device_excl_bkg & screen_maybe_0.2\")\n",
    "print(classification_report(df[\"device\"], df[\"screen_maybe_0.2\"]))\n",
    "print(f\"AUC: {roc_auc_score(df['device'], df['screen_maybe_0.2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
