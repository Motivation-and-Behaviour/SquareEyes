{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOFace\n",
    "\n",
    "Uses code from:\n",
    "* https://github.com/sthanhng/yoloface\n",
    "* https://github.com/fyr91/face_detection/blob/master/detect_yolov3.py\n",
    "\n",
    "Useful: \n",
    "* https://towardsdatascience.com/real-time-face-recognition-with-cpu-983d35cc3ec5\n",
    "* https://github.com/fyr91/face_detection\n",
    "* https://github.com/sthanhng/yoloface\n",
    "* https://github.com/dannyblueliu/YOLO-Face-detection\n",
    "* https://www.baseapp.com/deepsight-image-recognition-sdk/deepsight-face-sdk-download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.4\n",
    "IMG_WIDTH = 416\n",
    "IMG_HEIGHT = 416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "def get_outputs_names(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layers_names = net.getLayerNames()\n",
    "\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected\n",
    "    # outputs\n",
    "    return [layers_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "# Draw the predicted bounding box\n",
    "def draw_predict(frame, conf, left, top, right, bottom):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "    text = '{:.2f}'.format(conf)\n",
    "\n",
    "    # Display the label at the top of the bounding box\n",
    "    label_size, base_line = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "    top = max(top, label_size[1])\n",
    "    cv2.putText(frame, text, (left, top - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.4,\n",
    "                (255, 255, 255), 1)\n",
    "    \n",
    "    # Add the blurring in\n",
    "    roi = frame[top : bottom, left : right]\n",
    "\n",
    "    # Blur the coloured image\n",
    "    blur = cv2.GaussianBlur(roi, (101, 101), 0)\n",
    "\n",
    "    # Insert the blurred section back into image\n",
    "    frame[top : bottom, left : right] = blur\n",
    "\n",
    "\n",
    "def post_process(frame, outs, conf_threshold, nms_threshold):\n",
    "    frame_height = frame.shape[0]\n",
    "    frame_width = frame.shape[1]\n",
    "\n",
    "    # Scan through all the bounding boxes output from the network and keep only\n",
    "    # the ones with high confidence scores. Assign the box's class label as the\n",
    "    # class with the highest score.\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    final_boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * frame_width)\n",
    "                center_y = int(detection[1] * frame_height)\n",
    "                width = int(detection[2] * frame_width)\n",
    "                height = int(detection[3] * frame_height)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant\n",
    "    # overlapping boxes with lower confidences.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold,\n",
    "                               nms_threshold)\n",
    "\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        final_boxes.append(box)\n",
    "        left, top, right, bottom = refined_box(left, top, width, height)\n",
    "        # draw_predict(frame, confidences[i], left, top, left + width,\n",
    "        #              top + height)\n",
    "        draw_predict(frame, confidences[i], left, top, right, bottom)\n",
    "    return final_boxes\n",
    "\n",
    "\n",
    "def refined_box(left, top, width, height):\n",
    "    right = left + width\n",
    "    bottom = top + height\n",
    "\n",
    "    original_vert_height = bottom - top\n",
    "    top = int(top + original_vert_height * 0.15)\n",
    "    bottom = int(bottom - original_vert_height * 0.05)\n",
    "\n",
    "    margin = ((bottom - top) - (right - left)) // 2\n",
    "    left = left - margin if (bottom - top - right + left) % 2 == 0 else left - margin - 1\n",
    "\n",
    "    right = right + margin\n",
    "\n",
    "    return left, top, right, bottom\n",
    "\n",
    "def blurFacesYOLO(frame, CONF_THRESHOLD):\n",
    "      \n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255, (IMG_WIDTH, IMG_HEIGHT),[0, 0, 0], 1, crop=False)\n",
    "    # Sets the input to the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Runs the forward pass to get output of the output layers\n",
    "    outs = net.forward(get_outputs_names(net))\n",
    "    \n",
    "    # Remove the bounding boxes with low confidence\n",
    "    faces = post_process(frame, outs, CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "    \n",
    "    return frame.astype(np.uint8)\n",
    "\n",
    "def blursingle(image, CONF_THRESHOLD):\n",
    "    cv2.imwrite(os.path.splitext(image)[0] + \"_blurred.jpg\",\n",
    "               blurFacesYOLO(cv2.imread(image), CONF_THRESHOLD))\n",
    "\n",
    "def blurfolder(folder, CONF_THRESHOLD):\n",
    "    files = glob.glob(os.path.join(folder,\"*.jpg\"))\n",
    "    for file in files:\n",
    "        blursingle(file, CONF_THRESHOLD)\n",
    "        \n",
    "def blurvideo(video, CONF_THRESHOLD):\n",
    "    # Get first frame\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    \n",
    "    \n",
    "    video_writer = cv2.VideoWriter(os.path.join(os.path.splitext(video)[0] + \"_blurred.avi\"),\n",
    "                                       cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'),\n",
    "                                       cap.get(cv2.CAP_PROP_FPS), (\n",
    "                                           round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                                           round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "    # While there are still frames to process...\n",
    "    while True:\n",
    "        has_frame, frame = cap.read()\n",
    "\n",
    "        # Stop the program if reached end of video\n",
    "        if not has_frame:\n",
    "            break\n",
    "            \n",
    "        video_writer.write(blurFacesYOLO(frame,CONF_THRESHOLD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model config\n",
    "net = cv2.dnn.readNetFromDarknet(os.path.abspath(\"/Users/tasanders/Documents/weights/yolov3-face.cfg\"),\n",
    "                             os.path.abspath(\"/Users/tasanders/Documents/weights/yolov3-wider_16000.weights\")) # Weights from yoloface github page\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = \"/Users/tasanders/Documents/Face_blurring/CC4B73632D38_2021_0210_144434_434_0001.jpg\"\n",
    "blursingle(path_to_image, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1.47 s, total: 1min 12s\n",
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_folder = \"/Users/tasanders/Documents/face_test\"\n",
    "blurfolder(path_to_folder,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video = \"/path_to_video/video.mp4\"\n",
    "blurvideo(path_to_video, 0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
