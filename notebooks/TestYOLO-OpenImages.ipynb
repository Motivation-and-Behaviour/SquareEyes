{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "LABELS = open(\"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/openimages.names\").read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights and config\n",
    "configpath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov3-openimages.cfg\"\n",
    "weightspath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov3-openimages.weights\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(configpath, weightspath)\n",
    "\n",
    "# Determine the output layer names\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0]-1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and save to df\n",
    "def predict_and_save(folder, coded_data, conf_thresh=0.1, nms_thresh=0.15):\n",
    "    predict_files = glob.glob(folder + \"/*/*.jpg\")\n",
    "\n",
    "    predictor, prob, image_id = [], [], []\n",
    "    final = pd.DataFrame(columns=[\"id\", \"prediction\", \"confidence\", \"image\"])\n",
    "\n",
    "    not_coded = []\n",
    "\n",
    "    for index, image in enumerate(predict_files):\n",
    "        if coded_data[\"filename\"].str.contains(os.path.basename(image)).any():\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Working on image {index} of {len(predict_files)-1}\")\n",
    "\n",
    "            im = cv2.imread(image)\n",
    "            (H, W) = im.shape[:2]\n",
    "\n",
    "            # Create the blob\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                im, 1 / 255.0, (416, 416), swapRB=True, crop=False\n",
    "            )\n",
    "            net.setInput(blob)\n",
    "            layerOutputs = net.forward(ln)\n",
    "\n",
    "            # Translate the predictions\n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            classIDs = []\n",
    "\n",
    "            for output in layerOutputs:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    classID = np.argmax(scores)\n",
    "                    confidence = scores[classID]\n",
    "\n",
    "                    if confidence > conf_thresh:\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "                        # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "\n",
    "            # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, nms_thresh)\n",
    "\n",
    "            # Append to df\n",
    "            if len(idxs):\n",
    "                for i in idxs.flatten():\n",
    "                    final = final.append(\n",
    "                        {\n",
    "                            \"id\": classIDs[i],\n",
    "                            \"prediction\": LABELS[classIDs[i]],\n",
    "                            \"confidence\": confidences[i],\n",
    "                            \"image\": os.path.basename(image),\n",
    "                        },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "            else:  # no predictions made\n",
    "                final = final.append(\n",
    "                    {\n",
    "                        \"id\": None,\n",
    "                        \"prediction\": None,\n",
    "                        \"confidence\": None,\n",
    "                        \"image\": os.path.basename(image),\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test against Bridget's coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image 2892 of 4495\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coded_data = pd.read_csv(\"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/Screen Time Coding Data - Device.csv\")\n",
    "folder = \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images\"\n",
    "df = predict_and_save(folder, coded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()\n",
    "df.to_csv(\n",
    "    \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/YOLO-OpenImages.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maybe = [\n",
    "    \"Computer keyboard\",\n",
    "    \"Printer\",\n",
    "    \"Computer mouse\",\n",
    "    \"Remote control\",\n",
    "]\n",
    "\n",
    "cat_def = [\n",
    "    \"Laptop\",\n",
    "    \"Computer monitor\",\n",
    "    \"Mobile phone\",\n",
    "    \"Television\",\n",
    "    \"Tablet computer\",\n",
    "    \"Ipod\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['screen_def'] = np.where(df[\"prediction\"].isin(cat_def),1,0)\n",
    "df['screen_maybe'] = np.where(df[\"prediction\"].isin(cat_def + cat_maybe),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_def(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_def\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def conf_maybe(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_maybe\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(0.1, 0.501,0.05):\n",
    "    df[\"screen_def_\"+str(x)] = df.apply(conf_def, confthresh=x, axis=1)\n",
    "    df[\"screen_maybe_\"+str(x)] = df.apply(conf_maybe, confthresh=x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(coded_data,left_on=\"image\", right_on=\"filename\")\n",
    "df.drop(columns=\"filename\", inplace=True)\n",
    "df[[\"device\",\"device_excl_bkg\"]] = df[[\"device\",\"device_excl_bkg\"]].astype(int)\n",
    "df = df.drop(columns=[\"prediction\",\"confidence\",\"id\"]).groupby([\"image\"]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_devices = ['device', 'device_excl_bkg']\n",
    "predicted_devices = df.drop(columns=['device', 'device_excl_bkg','screen_def', 'screen_maybe',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for true_device in true_devices:\n",
    "    for predicted_device in predicted_devices:\n",
    "        print(f\"Comparing: {true_device} & {predicted_device}\")\n",
    "        print(classification_report(df[true_device], df[predicted_device]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Comparing: device & screen_maybe_0.3\")\n",
    "print(classification_report(df[\"device\"], df[\"screen_maybe_0.3\"]))\n",
    "print(f\"AUC: {roc_auc_score(df['device'], df['screen_maybe_0.3'])}\")\n",
    "print(f\"Comparing: device_excl_bkg & screen_maybe_0.3\")\n",
    "print(classification_report(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))\n",
    "print(cohen_kappa_score(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))\n",
    "print(f\"AUC: {roc_auc_score(df['device_excl_bkg'], df['screen_maybe_0.3'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
