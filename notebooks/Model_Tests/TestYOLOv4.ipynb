{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is on hold. Need an experimental build of Opencv (3.4.11) before it can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "from yolov4.tf import YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOv4()\n",
    "yolo.classes = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/coco.names\"\n",
    "\n",
    "yolo.make_model()\n",
    "yolo.load_weights(\n",
    "    \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov4.weights\",\n",
    "    weights_type=\"yolo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/YOLO_Training/Test Data/1106vid2image00544.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4405.44 ms\n",
      "YOLOv4: Inference is finished\n"
     ]
    }
   ],
   "source": [
    "x = yolo.inference(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "LABELS = open(\"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/coco.names\").read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) ../modules/dnn/src/darknet/darknet_io.cpp:821: error: (-212:Parsing error) Unsupported activation: mish in function 'ReadDarknetFromCfgStream'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8c110f7bf8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweightspath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov4.weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightspath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Determine the output layer names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) ../modules/dnn/src/darknet/darknet_io.cpp:821: error: (-212:Parsing error) Unsupported activation: mish in function 'ReadDarknetFromCfgStream'\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and config\n",
    "configpath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov4.cfg\"\n",
    "weightspath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov4.weights\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(configpath, weightspath)\n",
    "\n",
    "# Determine the output layer names\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0]-1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and save to df\n",
    "def predict_and_save(folder, coded_data, conf_thresh=0.25, nms_thresh=0.2):\n",
    "    predict_files = glob.glob(folder + \"/*/*.jpg\")\n",
    "\n",
    "    predictor, prob, image_id = [], [], []\n",
    "    final = pd.DataFrame(columns=[\"id\", \"prediction\", \"confidence\", \"image\"])\n",
    "\n",
    "    not_coded = []\n",
    "\n",
    "    for index, image in enumerate(predict_files):\n",
    "        if coded_data[\"filename\"].str.contains(os.path.basename(image)).any():\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Working on image {index} of {len(predict_files)-1}\")\n",
    "\n",
    "            im = cv2.imread(image)\n",
    "            (H, W) = im.shape[:2]\n",
    "\n",
    "            # Create the blob\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                im, 1 / 255.0, (416, 416), swapRB=True, crop=False\n",
    "            )\n",
    "            net.setInput(blob)\n",
    "            layerOutputs = net.forward(ln)\n",
    "\n",
    "            # Translate the predictions\n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            classIDs = []\n",
    "\n",
    "            for output in layerOutputs:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    classID = np.argmax(scores)\n",
    "                    confidence = scores[classID]\n",
    "\n",
    "                    if confidence > conf_thresh:\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "                        # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "\n",
    "            # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, nms_thresh)\n",
    "\n",
    "            # Append to df\n",
    "            if len(idxs):\n",
    "                for i in idxs.flatten():\n",
    "                    final = final.append(\n",
    "                        {\n",
    "                            \"id\": classIDs[i],\n",
    "                            \"prediction\": LABELS[classIDs[i]],\n",
    "                            \"confidence\": confidences[i],\n",
    "                            \"image\": os.path.basename(image),\n",
    "                        },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "            else:  # no predictions made\n",
    "                final = final.append(\n",
    "                    {\n",
    "                        \"id\": None,\n",
    "                        \"prediction\": None,\n",
    "                        \"confidence\": None,\n",
    "                        \"image\": os.path.basename(image),\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test against Bridget's coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image 4495 of 4495\n",
      "CPU times: user 2h 4min 30s, sys: 1min 46s, total: 2h 6min 17s\n",
      "Wall time: 34min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coded_data = pd.read_csv(\"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/Screen Time Coding Data - Device.csv\")\n",
    "folder = \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images\"\n",
    "df = predict_and_save(folder, coded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maybe = [\n",
    "    \"mouse\",\n",
    "    \"remote\",\n",
    "    \"keyboard\",\n",
    "]\n",
    "\n",
    "cat_def = [\n",
    "    \"tvmonitor\",\n",
    "    \"laptop\",\n",
    "    \"cell phone\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['screen_def'] = np.where(df[\"prediction\"].isin(cat_def),1,0)\n",
    "df['screen_maybe'] = np.where(df[\"prediction\"].isin(cat_def + cat_maybe),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_def(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_def\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def conf_maybe(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_maybe\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(0.3, 0.8,0.05):\n",
    "    df[\"screen_def_\"+str(x)] = df.apply(conf_def, confthresh=x, axis=1)\n",
    "    df[\"screen_maybe_\"+str(x)] = df.apply(conf_maybe, confthresh=x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(coded_data,left_on=\"image\", right_on=\"filename\")\n",
    "df.drop(columns=\"filename\", inplace=True)\n",
    "df[[\"device\",\"device_excl_bkg\"]] = df[[\"device\",\"device_excl_bkg\"]].astype(int)\n",
    "df = df.drop(columns=[\"prediction\",\"confidence\",\"id\"]).groupby([\"image\"]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['screen_def', 'screen_maybe', 'screen_def_0.3', 'screen_maybe_0.3',\n",
       "       'screen_def_0.35', 'screen_maybe_0.35',\n",
       "       'screen_def_0.39999999999999997', 'screen_maybe_0.39999999999999997',\n",
       "       'screen_def_0.44999999999999996', 'screen_maybe_0.44999999999999996',\n",
       "       'screen_def_0.49999999999999994', 'screen_maybe_0.49999999999999994',\n",
       "       'screen_def_0.5499999999999999', 'screen_maybe_0.5499999999999999',\n",
       "       'screen_def_0.5999999999999999', 'screen_maybe_0.5999999999999999',\n",
       "       'screen_def_0.6499999999999999', 'screen_maybe_0.6499999999999999',\n",
       "       'screen_def_0.7', 'screen_maybe_0.7', 'screen_def_0.7499999999999999',\n",
       "       'screen_maybe_0.7499999999999999', 'device', 'device_excl_bkg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_devices = ['device', 'device_excl_bkg']\n",
    "predicted_devices = df.drop(columns=['device', 'device_excl_bkg','screen_def', 'screen_maybe',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing: device & screen_def_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.96      0.74      1484\n",
      "        True       0.97      0.68      0.80      3011\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.78      0.82      0.77      4495\n",
      "weighted avg       0.85      0.77      0.78      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.96      0.77      1484\n",
      "        True       0.97      0.73      0.84      3011\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.81      0.85      0.80      4495\n",
      "weighted avg       0.86      0.81      0.81      4495\n",
      "\n",
      "Comparing: device & screen_def_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.96      0.73      1484\n",
      "        True       0.97      0.66      0.79      3011\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.81      0.76      4495\n",
      "weighted avg       0.85      0.76      0.77      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.96      0.76      1484\n",
      "        True       0.98      0.72      0.83      3011\n",
      "\n",
      "    accuracy                           0.80      4495\n",
      "   macro avg       0.80      0.84      0.79      4495\n",
      "weighted avg       0.86      0.80      0.80      4495\n",
      "\n",
      "Comparing: device & screen_def_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.97      0.72      1484\n",
      "        True       0.97      0.64      0.77      3011\n",
      "\n",
      "    accuracy                           0.75      4495\n",
      "   macro avg       0.77      0.80      0.74      4495\n",
      "weighted avg       0.84      0.75      0.75      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.96      0.75      1484\n",
      "        True       0.98      0.69      0.81      3011\n",
      "\n",
      "    accuracy                           0.78      4495\n",
      "   macro avg       0.79      0.83      0.78      4495\n",
      "weighted avg       0.85      0.78      0.79      4495\n",
      "\n",
      "Comparing: device & screen_def_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.97      0.71      1484\n",
      "        True       0.98      0.62      0.76      3011\n",
      "\n",
      "    accuracy                           0.73      4495\n",
      "   macro avg       0.77      0.79      0.73      4495\n",
      "weighted avg       0.84      0.73      0.74      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.97      0.74      1484\n",
      "        True       0.98      0.67      0.80      3011\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.79      0.82      0.77      4495\n",
      "weighted avg       0.85      0.77      0.78      4495\n",
      "\n",
      "Comparing: device & screen_def_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.97      0.70      1484\n",
      "        True       0.98      0.60      0.74      3011\n",
      "\n",
      "    accuracy                           0.72      4495\n",
      "   macro avg       0.76      0.79      0.72      4495\n",
      "weighted avg       0.83      0.72      0.73      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.97      0.73      1484\n",
      "        True       0.98      0.66      0.79      3011\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.81      0.76      4495\n",
      "weighted avg       0.85      0.76      0.77      4495\n",
      "\n",
      "Comparing: device & screen_def_0.5499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.98      0.69      1484\n",
      "        True       0.98      0.57      0.72      3011\n",
      "\n",
      "    accuracy                           0.71      4495\n",
      "   macro avg       0.76      0.78      0.71      4495\n",
      "weighted avg       0.83      0.71      0.71      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.5499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.98      0.72      1484\n",
      "        True       0.98      0.63      0.77      3011\n",
      "\n",
      "    accuracy                           0.74      4495\n",
      "   macro avg       0.77      0.80      0.74      4495\n",
      "weighted avg       0.84      0.74      0.75      4495\n",
      "\n",
      "Comparing: device & screen_def_0.5999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.98      0.68      1484\n",
      "        True       0.98      0.55      0.70      3011\n",
      "\n",
      "    accuracy                           0.69      4495\n",
      "   macro avg       0.75      0.76      0.69      4495\n",
      "weighted avg       0.83      0.69      0.70      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.5999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.98      0.70      1484\n",
      "        True       0.98      0.60      0.75      3011\n",
      "\n",
      "    accuracy                           0.73      4495\n",
      "   macro avg       0.77      0.79      0.73      4495\n",
      "weighted avg       0.84      0.73      0.73      4495\n",
      "\n",
      "Comparing: device & screen_def_0.6499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.98      0.67      1484\n",
      "        True       0.98      0.53      0.69      3011\n",
      "\n",
      "    accuracy                           0.68      4495\n",
      "   macro avg       0.74      0.75      0.68      4495\n",
      "weighted avg       0.82      0.68      0.68      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.6499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.98      0.69      1484\n",
      "        True       0.98      0.58      0.73      3011\n",
      "\n",
      "    accuracy                           0.71      4495\n",
      "   macro avg       0.76      0.78      0.71      4495\n",
      "weighted avg       0.84      0.71      0.72      4495\n",
      "\n",
      "Comparing: device & screen_def_0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.49      0.98      0.65      1484\n",
      "        True       0.98      0.50      0.66      3011\n",
      "\n",
      "    accuracy                           0.66      4495\n",
      "   macro avg       0.74      0.74      0.66      4495\n",
      "weighted avg       0.82      0.66      0.66      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.98      0.68      1484\n",
      "        True       0.98      0.55      0.71      3011\n",
      "\n",
      "    accuracy                           0.69      4495\n",
      "   macro avg       0.75      0.77      0.69      4495\n",
      "weighted avg       0.83      0.69      0.70      4495\n",
      "\n",
      "Comparing: device & screen_def_0.7499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.48      0.98      0.64      1484\n",
      "        True       0.98      0.47      0.63      3011\n",
      "\n",
      "    accuracy                           0.64      4495\n",
      "   macro avg       0.73      0.73      0.64      4495\n",
      "weighted avg       0.82      0.64      0.64      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.7499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.98      0.66      1484\n",
      "        True       0.98      0.52      0.68      3011\n",
      "\n",
      "    accuracy                           0.67      4495\n",
      "   macro avg       0.74      0.75      0.67      4495\n",
      "weighted avg       0.83      0.67      0.67      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.93      0.74      1573\n",
      "        True       0.95      0.68      0.80      2922\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.78      0.81      0.77      4495\n",
      "weighted avg       0.83      0.77      0.78      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.93      0.77      1573\n",
      "        True       0.95      0.74      0.83      2922\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.80      0.83      0.80      4495\n",
      "weighted avg       0.85      0.81      0.81      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.94      0.73      1573\n",
      "        True       0.95      0.67      0.78      2922\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.80      0.76      4495\n",
      "weighted avg       0.83      0.76      0.77      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.94      0.76      1573\n",
      "        True       0.95      0.72      0.82      2922\n",
      "\n",
      "    accuracy                           0.80      4495\n",
      "   macro avg       0.80      0.83      0.79      4495\n",
      "weighted avg       0.85      0.80      0.80      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.94      0.72      1573\n",
      "        True       0.95      0.64      0.77      2922\n",
      "\n",
      "    accuracy                           0.75      4495\n",
      "   macro avg       0.77      0.79      0.75      4495\n",
      "weighted avg       0.82      0.75      0.75      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.94      0.75      1573\n",
      "        True       0.96      0.70      0.81      2922\n",
      "\n",
      "    accuracy                           0.78      4495\n",
      "   macro avg       0.79      0.82      0.78      4495\n",
      "weighted avg       0.84      0.78      0.79      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.95      0.72      1573\n",
      "        True       0.96      0.62      0.75      2922\n",
      "\n",
      "    accuracy                           0.74      4495\n",
      "   macro avg       0.77      0.78      0.74      4495\n",
      "weighted avg       0.82      0.74      0.74      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.94      0.74      1573\n",
      "        True       0.96      0.68      0.80      2922\n",
      "\n",
      "    accuracy                           0.77      4495\n",
      "   macro avg       0.79      0.81      0.77      4495\n",
      "weighted avg       0.84      0.77      0.78      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.95      0.71      1573\n",
      "        True       0.96      0.60      0.74      2922\n",
      "\n",
      "    accuracy                           0.72      4495\n",
      "   macro avg       0.76      0.78      0.72      4495\n",
      "weighted avg       0.82      0.72      0.73      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.95      0.74      1573\n",
      "        True       0.96      0.66      0.78      2922\n",
      "\n",
      "    accuracy                           0.76      4495\n",
      "   macro avg       0.78      0.80      0.76      4495\n",
      "weighted avg       0.83      0.76      0.77      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.5499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.96      0.70      1573\n",
      "        True       0.96      0.58      0.72      2922\n",
      "\n",
      "    accuracy                           0.71      4495\n",
      "   macro avg       0.76      0.77      0.71      4495\n",
      "weighted avg       0.82      0.71      0.71      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.5499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.95      0.73      1573\n",
      "        True       0.96      0.63      0.77      2922\n",
      "\n",
      "    accuracy                           0.75      4495\n",
      "   macro avg       0.77      0.79      0.75      4495\n",
      "weighted avg       0.83      0.75      0.75      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.5999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.96      0.69      1573\n",
      "        True       0.96      0.55      0.70      2922\n",
      "\n",
      "    accuracy                           0.70      4495\n",
      "   macro avg       0.75      0.76      0.70      4495\n",
      "weighted avg       0.81      0.70      0.70      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.5999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.96      0.72      1573\n",
      "        True       0.97      0.61      0.75      2922\n",
      "\n",
      "    accuracy                           0.73      4495\n",
      "   macro avg       0.77      0.79      0.73      4495\n",
      "weighted avg       0.83      0.73      0.74      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.6499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.96      0.68      1573\n",
      "        True       0.96      0.53      0.68      2922\n",
      "\n",
      "    accuracy                           0.68      4495\n",
      "   macro avg       0.74      0.75      0.68      4495\n",
      "weighted avg       0.81      0.68      0.68      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.6499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.96      0.71      1573\n",
      "        True       0.97      0.59      0.73      2922\n",
      "\n",
      "    accuracy                           0.72      4495\n",
      "   macro avg       0.76      0.77      0.72      4495\n",
      "weighted avg       0.82      0.72      0.72      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.96      0.67      1573\n",
      "        True       0.96      0.50      0.66      2922\n",
      "\n",
      "    accuracy                           0.66      4495\n",
      "   macro avg       0.73      0.73      0.66      4495\n",
      "weighted avg       0.80      0.66      0.66      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.96      0.69      1573\n",
      "        True       0.96      0.55      0.70      2922\n",
      "\n",
      "    accuracy                           0.70      4495\n",
      "   macro avg       0.75      0.76      0.70      4495\n",
      "weighted avg       0.82      0.70      0.70      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.7499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.97      0.65      1573\n",
      "        True       0.96      0.47      0.63      2922\n",
      "\n",
      "    accuracy                           0.64      4495\n",
      "   macro avg       0.73      0.72      0.64      4495\n",
      "weighted avg       0.80      0.64      0.64      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.7499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.97      0.68      1573\n",
      "        True       0.97      0.52      0.68      2922\n",
      "\n",
      "    accuracy                           0.68      4495\n",
      "   macro avg       0.74      0.74      0.68      4495\n",
      "weighted avg       0.81      0.68      0.68      4495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for true_device in true_devices:\n",
    "    for predicted_device in predicted_devices:\n",
    "        print(f\"Comparing: {true_device} & {predicted_device}\")\n",
    "        print(classification_report(df[true_device], df[predicted_device]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing: device & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.96      0.77      1484\n",
      "        True       0.97      0.73      0.84      3011\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.81      0.85      0.80      4495\n",
      "weighted avg       0.86      0.81      0.81      4495\n",
      "\n",
      "0.6157554480285313\n",
      "Comparing: device_excl_bkg & screen_maybe_0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.93      0.77      1573\n",
      "        True       0.95      0.74      0.83      2922\n",
      "\n",
      "    accuracy                           0.81      4495\n",
      "   macro avg       0.80      0.83      0.80      4495\n",
      "weighted avg       0.85      0.81      0.81      4495\n",
      "\n",
      "0.6092436327761945\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparing: device & screen_maybe_0.3\")\n",
    "print(classification_report(df[\"device\"], df[\"screen_maybe_0.3\"]))\n",
    "print(cohen_kappa_score(df[\"device\"], df[\"screen_maybe_0.3\"]))\n",
    "print(f\"Comparing: device_excl_bkg & screen_maybe_0.3\")\n",
    "print(classification_report(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))\n",
    "print(cohen_kappa_score(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6092436327761945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cohen_kappa_score(df[\"device_excl_bkg\"], df[\"screen_maybe_0.3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8465963972173907\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(df[\"device\"], df[\"screen_maybe_0.3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
