{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "LABELS = open(\"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolo.names\").read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights and config\n",
    "configpath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov3-spp.cfg\"\n",
    "weightspath = \"/Users/tasanders/Google Drive/Square Eyes (DP20)/5 - Data collection and management/Image Blurring Test/Yolo/yolov3-spp.weights\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(configpath, weightspath)\n",
    "\n",
    "# Determine the output layer names\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0]-1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and save to df\n",
    "def predict_and_save(folder, coded_data, conf_thresh=0.1, nms_thresh=0.15):\n",
    "    predict_files = glob.glob(folder + \"/*/*.jpg\")\n",
    "\n",
    "    predictor, prob, image_id = [], [], []\n",
    "    final = pd.DataFrame(columns=[\"id\", \"prediction\", \"confidence\", \"image\"])\n",
    "\n",
    "    not_coded = []\n",
    "\n",
    "    for index, image in enumerate(predict_files):\n",
    "        if coded_data[\"filename\"].str.contains(os.path.basename(image)).any():\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Working on image {index} of {len(predict_files)-1}\")\n",
    "\n",
    "            im = cv2.imread(image)\n",
    "            (H, W) = im.shape[:2]\n",
    "\n",
    "            # Create the blob\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                im, 1 / 255.0, (416, 416), swapRB=True, crop=False\n",
    "            )\n",
    "            net.setInput(blob)\n",
    "            layerOutputs = net.forward(ln)\n",
    "\n",
    "            # Translate the predictions\n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            classIDs = []\n",
    "\n",
    "            for output in layerOutputs:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    classID = np.argmax(scores)\n",
    "                    confidence = scores[classID]\n",
    "\n",
    "                    if confidence > conf_thresh:\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "                        # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "\n",
    "            # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, nms_thresh)\n",
    "\n",
    "            # Append to df\n",
    "            if len(idxs):\n",
    "                for i in idxs.flatten():\n",
    "                    final = final.append(\n",
    "                        {\n",
    "                            \"id\": classIDs[i],\n",
    "                            \"prediction\": LABELS[classIDs[i]],\n",
    "                            \"confidence\": confidences[i],\n",
    "                            \"image\": os.path.basename(image),\n",
    "                        },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "            else:  # no predictions made\n",
    "                final = final.append(\n",
    "                    {\n",
    "                        \"id\": None,\n",
    "                        \"prediction\": None,\n",
    "                        \"confidence\": None,\n",
    "                        \"image\": os.path.basename(image),\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test against Bridget's coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image 4495 of 4495\n",
      "CPU times: user 3h 6min 13s, sys: 1min 55s, total: 3h 8min 8s\n",
      "Wall time: 37min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coded_data = pd.read_csv(\"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/Screen Time Coding Data - Device.csv\")\n",
    "folder = \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images\"\n",
    "df = predict_and_save(folder, coded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()\n",
    "df.to_csv(\n",
    "    \"/Volumes/M&B/Screen_Time_Measure_Development/SNAP_IT/Coding Framework Test Images/YOLO-OpenImages.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maybe = [\n",
    "    \"Computer keyboard\",\n",
    "    \"Printer\",\n",
    "    \"Computer mouse\",\n",
    "    \"Remote control\",\n",
    "]\n",
    "\n",
    "cat_def = [\n",
    "    \"Laptop\",\n",
    "    \"Computer monitor\",\n",
    "    \"Mobile phone\",\n",
    "    \"Television\",\n",
    "    \"Tablet computer\",\n",
    "    \"Ipod\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['screen_def'] = np.where(df[\"prediction\"].isin(cat_def),1,0)\n",
    "df['screen_maybe'] = np.where(df[\"prediction\"].isin(cat_def + cat_maybe),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_def(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_def\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def conf_maybe(df, confthresh):\n",
    "    if df[\"confidence\"] > confthresh and df[\"screen_maybe\"]==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(0.1, 0.501,0.05):\n",
    "    df[\"screen_def_\"+str(x)] = df.apply(conf_def, confthresh=x, axis=1)\n",
    "    df[\"screen_maybe_\"+str(x)] = df.apply(conf_maybe, confthresh=x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(coded_data,left_on=\"image\", right_on=\"filename\")\n",
    "df.drop(columns=\"filename\", inplace=True)\n",
    "df[[\"device\",\"device_excl_bkg\"]] = df[[\"device\",\"device_excl_bkg\"]].astype(int)\n",
    "df = df.drop(columns=[\"prediction\",\"confidence\",\"id\"]).groupby([\"image\"]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_devices = ['device', 'device_excl_bkg']\n",
    "predicted_devices = df.drop(columns=['device', 'device_excl_bkg','screen_def', 'screen_maybe',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing: device & screen_def_0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.41      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.37      0.50      0.25      4495\n",
      "weighted avg       0.38      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.51      0.01      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.42      0.50      0.25      4495\n",
      "weighted avg       0.45      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.15000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.41      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.37      0.50      0.25      4495\n",
      "weighted avg       0.38      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.15000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.51      0.01      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.42      0.50      0.25      4495\n",
      "weighted avg       0.45      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.20000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.41      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.37      0.50      0.25      4495\n",
      "weighted avg       0.38      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.20000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.51      0.01      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.42      0.50      0.25      4495\n",
      "weighted avg       0.45      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.25000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.40      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.36      0.50      0.25      4495\n",
      "weighted avg       0.38      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.25000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.52      0.01      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.42      0.50      0.25      4495\n",
      "weighted avg       0.45      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.20      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.26      0.50      0.25      4495\n",
      "weighted avg       0.24      0.33      0.16      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.44      0.00      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.38      0.50      0.25      4495\n",
      "weighted avg       0.40      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.3500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      1.00      0.49      1484\n",
      "        True       0.22      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.28      0.50      0.25      4495\n",
      "weighted avg       0.26      0.33      0.16      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.3500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.41      0.00      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.37      0.50      0.25      4495\n",
      "weighted avg       0.38      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.40000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      1.00      0.50      1484\n",
      "        True       0.25      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.29      0.50      0.25      4495\n",
      "weighted avg       0.28      0.33      0.16      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.40000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.40      0.00      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.36      0.50      0.25      4495\n",
      "weighted avg       0.38      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.45000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      1.00      0.50      1484\n",
      "        True       0.29      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.31      0.50      0.25      4495\n",
      "weighted avg       0.30      0.33      0.16      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.45000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.47      0.00      0.01      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.40      0.50      0.25      4495\n",
      "weighted avg       0.42      0.33      0.17      4495\n",
      "\n",
      "Comparing: device & screen_def_0.5000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      1.00      0.50      1484\n",
      "        True       0.00      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.16      0.50      0.25      4495\n",
      "weighted avg       0.11      0.33      0.16      4495\n",
      "\n",
      "Comparing: device & screen_maybe_0.5000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.99      0.49      1484\n",
      "        True       0.43      0.00      0.00      3011\n",
      "\n",
      "    accuracy                           0.33      4495\n",
      "   macro avg       0.38      0.50      0.25      4495\n",
      "weighted avg       0.40      0.33      0.17      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.41      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.38      0.50      0.26      4495\n",
      "weighted avg       0.39      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.49      0.01      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.42      0.50      0.26      4495\n",
      "weighted avg       0.44      0.35      0.19      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.15000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.41      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.38      0.50      0.26      4495\n",
      "weighted avg       0.39      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.15000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.49      0.01      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.42      0.50      0.26      4495\n",
      "weighted avg       0.44      0.35      0.19      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.20000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.41      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.38      0.50      0.26      4495\n",
      "weighted avg       0.39      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.20000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.49      0.01      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.42      0.50      0.26      4495\n",
      "weighted avg       0.44      0.35      0.19      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.25000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.40      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.37      0.50      0.26      4495\n",
      "weighted avg       0.38      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.25000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.48      0.01      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.42      0.50      0.26      4495\n",
      "weighted avg       0.44      0.35      0.19      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.20      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.27      0.50      0.26      4495\n",
      "weighted avg       0.25      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.40      0.00      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.37      0.50      0.26      4495\n",
      "weighted avg       0.38      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.3500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      1.00      0.52      1573\n",
      "        True       0.22      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.29      0.50      0.26      4495\n",
      "weighted avg       0.27      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.3500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.41      0.00      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.38      0.50      0.26      4495\n",
      "weighted avg       0.39      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.40000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      1.00      0.52      1573\n",
      "        True       0.25      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.30      0.50      0.26      4495\n",
      "weighted avg       0.28      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.40000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.40      0.00      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.37      0.50      0.26      4495\n",
      "weighted avg       0.38      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.45000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      1.00      0.52      1573\n",
      "        True       0.29      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.32      0.50      0.26      4495\n",
      "weighted avg       0.31      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.45000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.47      0.00      0.01      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.41      0.50      0.26      4495\n",
      "weighted avg       0.43      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_def_0.5000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      1.00      0.52      1573\n",
      "        True       0.00      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.17      0.50      0.26      4495\n",
      "weighted avg       0.12      0.35      0.18      4495\n",
      "\n",
      "Comparing: device_excl_bkg & screen_maybe_0.5000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.99      0.52      1573\n",
      "        True       0.43      0.00      0.00      2922\n",
      "\n",
      "    accuracy                           0.35      4495\n",
      "   macro avg       0.39      0.50      0.26      4495\n",
      "weighted avg       0.40      0.35      0.18      4495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for true_device in true_devices:\n",
    "    for predicted_device in predicted_devices:\n",
    "        print(f\"Comparing: {true_device} & {predicted_device}\")\n",
    "        print(classification_report(df[true_device], df[predicted_device]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
